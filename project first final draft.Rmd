---
title: "Project 1 - Data Science for Economists"
author: "Lin, Oliver; Nazarov, Nazar; Priolo, Robert"
date: "Professor Rojas - Spring 2021"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
 
```{r}

options(digits = 2)
 
suppressMessages(library(POE5Rdata))
suppressMessages(library(dplyr))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(kableExtra))
suppressMessages(library(broom))
suppressMessages(library(psych))
 
#1
data("vegas5")
stat_sum <- describe(vegas5)[,-c(1,6,7,10)]
kable(stat_sum,
      caption = "Statistical Summary")
attach(vegas5)
 
 
```
 
 
# Question 1
 
 
*vegas5* dataset with variables *default*, *arm*, *refinance*, *lien2*, *term30*, *underwater*, *ltv*, *rate*, *amount* and *fico*.
 
 
Observations: 10,000 mortgage loan observations from Las Vegas, Nevada, single family homes, 2010
 
 
default         = 1 if payment late by 90+ days,
arm             = 1 if adjustable rate mortgage, 0 if fixed,
refinance       = 1 if loan is for a refinance of any type (0 if for purchase),
lien2           = 1 if 2nd lien mortage (0 if 1st lien),
term30          = 1 if 30 year mortgage (0 if 15 year mortgage),
underwater      = 1 if borrower estimated to owe more than property worth at time of observing (0 otherwise),
ltv             loan to value ratio of property at origination (percent),
rate            current interest rate on loan (percent),
amount          loan amount in $10,000 units,
fico            borrower's credit score at origination.
 
 
 
Based on the statistical summary table, 37% of households' payments were late by 90+ days,
38% of households had adjustable rate mortgages, almost more than half of households had loans for refinance of any type. In addition, 10% of households had 2nd lien mortgages, 85% of households had 30-yr mortgages, 82% of households owed morethan the property worth at time of observing. Mean loan-to-value ratio is 69% which is pretty good, with median 78% and max 109%. Mean rate on loans is 5.98%, with min, median and max 0.5%, 6.2% and 17%, respectively. A mean amount of borrowing is $245,600, with min of $11,000, median $211,000, max $7,500,000. Regarding FICO scores, mean score is 685, with min, median and max being 442, 687, 823, respectively. Variables that deal with dollar values are not normally distributed based on skewness and kurtosis stats.
 
 
Histograms
 
```{r setup,warning=FALSE, message=FALSE}
 
 
a5 <- ggplot(vegas5) +
  geom_histogram(aes(x = log(amount), fill = factor(lien2)), colour = "black")+
            theme_bw() + ylab("frequency") + labs(fill = "lien2")
 
a6 <- ggplot(vegas5) +
  geom_histogram(aes(x = log(amount), fill = factor(default)),
                 colour = "black") + labs(fill = "default") +
  theme_bw() + ylab("frequency")
 
a7 <- ggplot(vegas5) +
  geom_histogram(aes(x = log(amount), fill = factor(arm)),
                 colour = "black") + labs(fill = "arm") + theme_bw() +
  ylab("frequency")
 
a8 <- ggplot(vegas5) +
  geom_histogram(aes(x = log(amount), fill = factor(underwater)),
                 colour = "black") + labs(fill = "underwater") + theme_bw() +
  ylab("frequency")
 
grid.arrange(a5,a6,a7,a8, top = "Log(amount) Variation by Categorial Variable")
```
 
The lien graph shows that there are far less number of 2nd lien mortgages than 1st lien mortgages. And the loan amount of those 2nd lien mortgages are also smaller than the amount of the 1st lien mortgages. From the other 3 graphs we can see that: 1) there are less number of defaults than those that are paid on time; 2) there are less adjustable rate mortgages than fixed rate mortgages; 3) there are slightly less underwater mortgages than those that are not; 4) interestingly, the two cases for the 3 variables, default, arm, underwater, exhibits the similar variation.
 
 
```{r, results='hide'}
 
fd  <-  function(x) {
  n=length(x)
  r=IQR(x)
  2*r/n^(1/3)
}
 
a1 <- vegas5 %>% filter(amount < median(amount)) %>% ggplot(aes(x = amount)) +
  geom_histogram(colour = "black", fill = "steelblue") +
  aes(y = stat(count)/sum(stat(count))) +
  scale_y_continuous(labels=scales::percent) +
  ylab("Frequency (%)") +
  xlab("Amount (100K)") +
  facet_wrap(~refinance,
             labeller = labeller(refinance = c(`0`="loans for purchase",
                                               `1`="loans for refinance"))) +
  theme_bw() + ggtitle("Frequency of Loans for Single Family Homes by Amount (less than 210K)")
 
 
a2 <- vegas5 %>% filter(amount > median(amount) & amount < 180) %>% ggplot(aes(x = amount)) +
  geom_histogram( colour = "black", fill = "steelblue") +
  aes(y = stat(count)/sum(stat(count))) +
  scale_y_continuous(labels=scales::percent) + xlab("Amount (100K)") +
  ylab("Frequency(%)") + facet_wrap(~refinance,
                         labeller = labeller(refinance = c(`0`="loans for purchase",
                                                           `1`="loans for refinance"))) +
  theme_bw() + ggtitle("Frequency of Loans for Single Family
                       Homes by Amount (greater than 210K & less than 1.8Mn)")
grid.arrange(a1, a2)
 
 
 
```
 
In this plot, three variables are plotted: amount, frequency of occurrence and refinance.
We can observe a peculiar trend when plotting observations based on the filters.
Households with less than 210K borrowed seem to exhibit a left-skewness whereas households who borrowed between 210K and 1.8Mn, skewness to the right, which indicates that both distributions are not normal.
 
 
 
 
```{r}
 
suppressMessages(library(PupillometryR))
a4 <- ggplot(vegas5, aes(x = factor(default),
                   y = fico, colour = factor(arm))) + geom_jitter(alpha = 0.20) +
   geom_boxplot() + xlab("Default") +
  theme_bw() + labs(colour = "arm") +
  ylab("FICO")
 
 
a3 <- ggplot(vegas5,aes(x = factor(term30), y = fico, colour = factor(lien2))) +
  geom_jitter(alpha = 0.20) +
 geom_boxplot() + ylab("FICO") + xlab("30-yr Mortage") +
  labs(colour = "2nd Lien") +
   theme_bw()
 
grid.arrange(a4,a3, ncol = 2,
             top = "FICO Score Differences Based on Default, 30-yr Mortage, Adjustable Rate, 2nd Lien")
 
```
 
In this plot, five variables are plotted in the form of boxplots. On the left, we can see FICO scores tend to be higher for those who were not late on their payments (90+ days) and with adjustable rate mortgages (quite surprising). This may be due to the fact that interest rates might have been lower during that period. What is not surprising to observe is that FICO scores for those who were late on their payments are lower, but tend to be similar whether those with lower scores had an adjustable rates or not.
 
On the right, we can see that individuals who applied for a 15-year mortgage have a slightly higher FICO score than the ones with 30-year mortgage. This is intuitive because 15-year mortgages tend to have a higher periodic payment than 30-year, which banks would understandably require a higher FICO score. And in the same boxplot, we can see that 1st lien mortgages have a noticeably lower FICO score than the 2nd lien mortgages. This is the case probably because in the case of default, 1st lien would be paid in full before 2nd lien would be paid. Therefore 2nd lien would require a higher FICO score.
 
 
```{r, results="hide"}
 
fd(rate)
ggplot(vegas5) +
  geom_histogram(aes(x = rate), binwidth = fd, colour = "black", fill = "steelblue") +
  aes(y = ..count../sum(count)) +
  scale_y_continuous(labels = scales::percent) +
  ylab("Frequency (%)") + xlab("Rates (%)") + facet_grid(refinance~underwater, switch = "both",
                                         labeller = labeller(
                                           refinance = c(`0` = "for purchase",
                                                          `1`= "for refinance"),
                                           underwater = c(`0` = "not owe more than property worth",
                                                          `1` = "owes more than property worth")
                                         )) + theme_bw() +
  ggtitle("Rates for Households Based on Refinance Goals and Underwater Disposition")
 
```
 
As we can see, households who owe more than property worth tend to have higher mortgage rates than their non-underwater counterparts.
 
 
 
```{r}
 
ggplot(vegas5, aes(x = fico, y = ltv, colour = factor(term30))) +
  geom_point(alpha =0.20) +
  geom_smooth() +
  facet_grid(arm~underwater,
             switch = "both",
             labeller = labeller(arm = c(`0` = "fixed rate",
                             `1`= "adjustable rate"),
               underwater = c(`0` = "not owe more than property worth",
                              `1` = "owes more than property worth"))) +
  xlab("FICO") + ylab("Loan-to-Value") +
  labs(colour = "30-yr mortage") +
  ggtitle("Loan-to-Value vs FICO scores (30-year Mortage = 1, 15-yr Mortgage = 0)") +
  theme_bw()
 
```
 
Here we can observe that households who owe more than property worth have higher loan-to-value ratios,
but the relationship betwee FICO scores and ltv's is unclear where as for those who do not owe more than property worth tend to have lower ltv ratios and the relationship between FICO scores and ltv's is somewhat negative, specifically for those who did not take out a 30-yr mortgage in the first place. Although it looks somewhat positive for those who took out 30-yr mortgages. We can deduce that there is a larger concentration of households who possess 30-yr mortages and owe more than property worth. This potentially can be a byproduct of the 2007-2008 housing market crash, i.e. people owing more than their house is worth.
 
 
 
```{r}
 
#correlation plot
suppressMessages(library(corrplot))
corrplot(cor(vegas5[,7:10]))
 
 
```
 
There are some interesting correlations between variables in the correlation plot. First, we can see a slight positive correlation between FICO score and loan amount. This is explainable because banks want higher credibility for larger loans. We can also see a negative correlation between FICO score and mortgage rate. This might be explained by banks being more willing to give low rates to more creditworthy borrowers. Additionally, we can see a small positive correlation between FICO score and loan amount. Obviously, banks tend to grant larger loans to borrowers with a higher credit score.
 
 
 
```{r}
#scatterplot
suppressMessages(library(car))
scatterplotMatrix(vegas5[,7:10], col = "steelblue",
                  ellipse = TRUE)
 
```
 
Similar to descriptions for the correlation plot above, this scatterplot matrix confirms our initial observations regarding variable correlations. First, looking at the upper diagonal of the matrix, we can see that rate and loan-to-value are negatively correlated. Second, amount and loan-to-value tend to be positively correlated since the regression line is seen on the left corner inside the micro-scatter plot. Third, there might be a negative correlation between FICO and loan-to-value, it is so small that it looks almost horizontal, which leads us to believe that this correlation is negligible.
 
# Question 2
 
```{r}
#initial setup
 
t.critical <- function(alpha, df, tail = "two") {
  if(tail == "two"){
    result <- qt(1-alpha/2  , df)
  } else if(tail == "right"){
    result <- qt(1-alpha  , df)
  } else if(tail=="left"){
    result <- qt(alpha  , df)
  }
  return(result)
}
#data
library(POE5Rdata)
data("vegas5")
attach(vegas5)
#Libraries
library(POE5Rdata)
library(dynlm) #for the `dynlm()` function
library(broom) #for `glance(`) and `tidy()`
library(lmtest) #bgtest()
library(stargazer) #stargazer()
library(knitr) #kable()
library(sandwich) #coeftest()
library(car) #deltamethod
library(forecast) #forecast()
```
 
 
 
#Question 2
 
Estimate a multiple linear regression model that includes all the main effects only (i.e., no
interactions nor higher order terms). We will use this model as a baseline. Comment on
the statistical and economic significance of your estimates. Also, make sure to provide an
interpretation of your estimates.
 
```{r}
 
suppressMessages(library(stargazer))
model.lm<- lm(default~arm+refinance+lien2+term30+underwater+ltv+rate+amount+fico)
#testing against GLM model due to binomial coef
model.glm<- glm(default~arm+refinance+lien2+term30+underwater+ltv+rate+amount+fico, family = "binomial")
#standard model summaries
summary(model.lm)
summary(model.glm)
#stargazer quick comparison
stargazer(model.lm, model.glm,
          type = "text",
          column.labels = c("LM", "GLM"),
          model.names=FALSE, dep.var.labels.include=FALSE,
          dep.var.caption      =c("models"), digits=5,
          intercept.top = TRUE)
```
Insignificant variables: arm, term30, amount
 
Arm: interesting that arm is not significant since our intuition is that people
who obtain an arm loan with a lower initial payment would cause higher defaults
if the arm causes mortgage payments to increase from its initial value
 
term30: may be insignificant for a few reasons. First, the amount of records
with 15 years is low compared the entire data set. Second, borrowers with 15 year
loans may be more financially fit than 30 year borrowers. Third, the borrow can
refinance to a 30 years to lower payments if needed.
 
amount: we are surprised that amount is insignificant as my intuition would be borrowers
with high loan amounts would have a higher likelihood to default
 
# Question 3
 
```{r}
#initial setup
 
t.critical <- function(alpha, df, tail = "two") {
  if(tail == "two"){
    result <- qt(1-alpha/2  , df)
  } else if(tail == "right"){
    result <- qt(1-alpha  , df)
  } else if(tail=="left"){
    result <- qt(alpha  , df)
  }
  return(result)
}
#data
library(POE5Rdata)
data("vegas5")
attach(vegas5)
#Libraries
suppressMessages(library(POE5Rdata))
suppressMessages(library(broom)) #for `glance(`) and `tidy()`
suppressMessages(library(lmtest)) #bgtest()
suppressMessages(library(stargazer)) #stargazer()
suppressMessages(library(knitr)) #kable()
suppressMessages(library(sandwich)) #coeftest()
suppressMessages(library(car)) #deltamethod qqPlot()
suppressMessages(library(forecast)) #forecast()
suppressMessages(library(olsrr)) #ols_plot_resid_lev()
```
 
 
 
```{r}
 
model.lm<- lm(default~arm+refinance+lien2+term30+underwater+ltv+rate+amount+fico)
#visual
# qqPlot(model.lm, id=list(n=3))
#Bonferroni test
outlierTest(model.lm)
 
influenceIndexPlot(model.lm, id=list(n=3),vars="hat")
#ols plots
ols_plot_resid_lev(model.lm)
ols_plot_dfbetas(model.lm)
ols_plot_dffits(model.lm)
 
```
 
# Question 4


 
Based on the output in the table above, lm regression makes more sense, since if we set all the variables to zero, the probability of default equals 0.50, which is equivalent to a flip of a coin. This, intuitively, makes more sense, as it adds more randomness to the event and also because probabilities are positive values in the interval between (0,1). Therefore, we will be using the lm model to answer questions that follow.
 
 
```{r}
suppressMessages(library(leaps))
suppressMessages(library(AER))
suppressMessages(library(broom))
suppressMessages(library(Boruta))
model.lm<- lm(default~arm+refinance+lien2+term30+underwater+ltv+rate+amount+fico,
              data = vegas5)
lm.mallows.cp <- regsubsets(default~arm+refinance+lien2+term30+underwater+ltv+rate+amount+fico,data = vegas5, method = c("exhaustive"), nbest = 8)
plot(lm.mallows.cp)
subsets <- subsets(lm.mallows.cp, statistic = "cp", legend = F, main = "Mallows CP",
                   ylim = c(0,12))
 
 
Boruta.res <- Boruta(default~.,
                     data = vegas5,
                     doTrace = 3,
                     maxRuns = 777)
plot(Boruta.res)
attStats(Boruta.res)[order(-attStats(Boruta.res)$meanImp),]
```
It looks like mallows CP prefers 7 predictor variables, they are: arm, refinance, lien2, underwater,ltv,rate,fico. In addition, based on Boruta's importance plot, lien2 is rejected as a predictor variable. Hence, we'll trust Boruta that performed 777 max runs and proceed to estimate a model without lien2.
 
# Question 5
 
```{r}
suppressMessages(library(car))
updated.lm <- lm(default~arm+refinance+term30+underwater+ltv+rate+amount+fico,
              data = vegas5)
kable(tidy(summary(updated.lm)))
 
vif(updated.lm)
 
```
 
It seems as though VIF's look fine and none are above 4 which we use as a threshold in this case. Therefore, we will not be removing any variables since there is not a reason to believe that there is strong multicollinearity.
 
# Question 6
 
```{r}
 
ggplot() +
  geom_point(aes(x = updated.lm$fitted.values,
                 y = resid(updated.lm)))
qqPlot(updated.lm)
 
 
```
Again, nothing too suspicious. QQplot reveals that our observations follow a logistic curve.
 
# Question 7
 
```{r}
resettest(updated.lm, power = 2, type = "regressor")
 
```
Based on the results, we need to consider including higher-order terms.
 
 
# Question 8
 
```{r}

#accounting for heteroskedasticity 

bptest(updated.lm)

p <- fitted(updated.lm)
p[p<0.01] <- 0.01 #truncating probabilities that don't fall in (0,1) interval
p[p>0.99] <- 0.99
sigma.sq <- p*(1-p)
weight <- 1/sigma.sq
 
updated.lm.fgls <- lm(default~arm+refinance+term30+underwater+ltv+rate+amount+fico, #re-estimating the model
              data = vegas5, weights = weight)
bptest(updated.lm.fgls)
summary(updated.lm.fgls)
kable(tidy(updated.lm.fgls), caption = "Updated Linear Model-GLS with Boruta-selected Variables")


#we believe we can do better in terms of coefficient significance
p1 <- fitted(updated.lm)
p1[p1 < 0.01 | p1 > 0.99] <- NA
sigsq <- p1*(1-p1)
w <- 1/sigsq

updated.lm.fgls.omit <- lm(default~arm+refinance+term30+underwater+ltv+rate+amount+fico, #re-estimating the model
              data = vegas5, weights = w)

summary(updated.lm.fgls.omit) #much better
kable(tidy(updated.lm.fgls.omit), 
      caption = "Linear GLS Model with Truncated Fitted Values") #this is the model we will keep

#linear hypothesis test indicates that we reject H0
linearHypothesis(updated.lm.fgls.omit, 
                 hypothesis.matrix = c("term30", 
                                       "arm", 
                                       "amount"))
#here, linear hypothesis test shows that arm = 0
linearHypothesis(updated.lm.fgls.omit, 
                 hypothesis.matrix = c("arm"))


#to summarize
stargazer(model.lm, model.glm, updated.lm, updated.lm.fgls, updated.lm.fgls.omit,
          type = "text",
          model.names=F, digits=3,
          intercept.bottom = F, 
          column.labels = c("OLS", "Logistic", 
                            "Boruta-chosen OLS", 
                            "OLS GLS", 
                            "OLS GLS-Omit"), 
          dep.var.caption = "Probability of Default", 
          dep.var.labels.include = F, 
          selection.equation = T)


```

 
Based on the Breusch-Pagan Test, heteroskedasticity is present as expected. After removing the variables that are not statistically significant, we are confident that our estimates for the coefficients are unbiased. By applying Heteroskedasticity-Consistent standard errors and feasible generalized least squares, we have accounted for heteroskedasticity.  And as \(n\rightarrow\infty\) our standard errors, t-tests, interval estimates are valid in large samples. 



# Question 9

```{r}


options(digits=3)
lm.interaction <- lm(default~refinance+term30+underwater+ltv+rate*arm+amount+
                    fico, #re-estimating the model
              data = vegas5)

summary(lm.interaction) #seems a much better model compared to others


b1 = BIC(model.lm)
b2 = BIC(model.glm)
b3 = BIC(updated.lm)
b4 = BIC(updated.lm.fgls)
b5 = BIC(updated.lm.fgls.omit)
b6 = BIC(lm.interaction)

c1 = AIC(model.lm)
c2 = AIC(model.glm)
c3 = AIC(updated.lm)
c4 = AIC(updated.lm.fgls)
c5 = AIC(updated.lm.fgls.omit)
c6 = AIC(lm.interaction)

v1 = c(b1,b2,b3,b4,b5,b6)
v2 = c(c1,c2,c3,c4,c5,c6)
df = cbind(v1,v2)

colnames(df) = c("BIC", "AIC")
rownames(df) = c("OLS", "Logistic", 
                            "Boruta-chosen OLS", 
                            "OLS GLS", 
                            "OLS GLS-Omit", 
                            "OLS Interaction")
kable(df)          

```

We have finally attained a better model where include an interaction term as well. It seems as though there is no need for any higher power terms, the model has been constructed with all terms being statistically significant, by adding higher power terms, we lose that significance. We will now proceed to apply cross-validation.


# Question 10

```{r}
set.seed(123)
row.number <- sample(1:nrow(vegas5), 0.75*nrow(vegas5))
training_set <- vegas5[row.number,]
test_set <- vegas5[-row.number,]
dim(training_set)


#calculating RMSE
sqrt(mean((training_set$default-predict(lm.interaction,training_set))^2)) 
#the predicted value is off by 0.45747

sqrt(mean((test_set$default-predict(lm.interaction,test_set))^2)) 
#on average the predicted value is off by 0.45011

suppressMessages(library(lmvar))
fit <- lm(default~refinance+term30+underwater+ltv+rate*arm+amount+
                    fico,
              data = vegas5, 
          x = TRUE, 
          y = TRUE)
          
cv.lm(fit, k = 10)
#RMSE 0.4550

```

# Question 11

Based on simple linear regression models we created, there are several variables which initially seem relevant to the default rate turned out to be statistically insignificant. They include the adjustable rate mortgage (arm), 30-year vs. 15-year mortgage, amount. Through removing outlier data points and transformation we eventually created models with higher order. We also omitted terms that seem to be irrelevant to the default rate, and finally we were able to include interaction terms. One interesting finding is that when we include interactions, term30 and arm became statistically significant, therefore for completeness, we decided to retain term30 and arm as predictor variables. And our conclusions is the following: 
Lien2 and amount are not statistically significant as predictor variables;
Refinancing loans have a slightly lower chance of default; 
30-year mortgages have slightly lower change of default;
Underwater mortgages have a higher default rate; 
Adjustable rate mortgages have higher default rate; 
LTV is positively correlated with default rate, specifically 1% increase in LTV ratio is correlated to 0.0033% increase in default rate;
The mortgage rate is positively correlated with default rate, 1% increase in the mortgage rate can lead to 0.0355% increase in default rate; 
Although the amount of the loan does not seem to have significant correlation with the default rate, we did find a positive correlation between default rate and the interaction between amount and mortgage rate. 1% increase in the product of amount and rate is expected to increase  0.0184% increase in default rate; 
Finally, there is also an expected negative correlation between FICO scores and the default rate, for an extra point increase in FICO is translated to 0.00112% decrease in default rate. 


